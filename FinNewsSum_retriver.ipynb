{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f4d354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv  # <-- ADD THIS LINE\n",
    "\n",
    "# LangChain Community for advanced loaders and vector stores\n",
    "from langchain_community.document_loaders import AsyncHtmlLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_transformers import Html2TextTransformer\n",
    "\n",
    "# LangChain OpenAI for Azure/OpenAI specific integrations\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "\n",
    "# Core LangChain components\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260e127",
   "metadata": {},
   "source": [
    "Initialize LLM and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e65f6078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM and Embeddings initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from your custom file\n",
    "load_dotenv(dotenv_path=\"OpenAI_APIkey.env\")\n",
    "\n",
    "# --- Initialize the LLM ---\n",
    "# The Azure clients will automatically find the environment variables\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-4.1-mini-2\",\n",
    "    model_name=\"gpt-4\",\n",
    "    temperature=0.9,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# --- Initialize the Embeddings ---\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=\"text-embedding-ada-002\",\n",
    "    chunk_size=1\n",
    ")\n",
    "\n",
    "print(\"LLM and Embeddings initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59aa99e",
   "metadata": {},
   "source": [
    "Load, Transform, and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fafc2cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 2/2 [00:00<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and split into 40 chunks from 2 URLs.\n"
     ]
    }
   ],
   "source": [
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.moneycontrol.com/news/business/economy/net-direct-tax-revenue-jumps-6-3-to-rs-11-89-lakh-crore-till-oct-12-13613684.html\",\n",
    "    \"https://www.moneycontrol.com/news/economy/policy/inflation-hits-over-eight-year-low-of-1-54-in-september-but-non-vegetarians-and-gold-buyers-feel-the-pinch-13613394.html\"\n",
    "]\n",
    "\n",
    "# Use AsyncHtmlLoader which is compatible with asyncio environments\n",
    "loader = AsyncHtmlLoader(urls)\n",
    "\n",
    "# Apply nest_asyncio to allow running asyncio loops within another loop\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Define an async function to load the data\n",
    "async def load_docs():\n",
    "    return await loader.aload()\n",
    "\n",
    "# Run the async function to get the documents\n",
    "all_documents = asyncio.run(load_docs())\n",
    "\n",
    "# Convert HTML to plain text\n",
    "html2text = Html2TextTransformer()\n",
    "all_documents = list(html2text.transform_documents(all_documents))\n",
    "\n",
    "# Split the data into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "docs = text_splitter.split_documents(all_documents)\n",
    "\n",
    "if not docs:\n",
    "    raise ValueError(\"No documents were loaded from the URLs.\")\n",
    "\n",
    "print(f\"Loaded and split into {len(docs)} chunks from {len(urls)} URLs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7650774",
   "metadata": {},
   "source": [
    "Create and Save FAISS Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86589de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved to 'faiss_index'.\n"
     ]
    }
   ],
   "source": [
    "vector_index = FAISS.from_documents(docs, embeddings)\n",
    "folder_path = \"faiss_index\"\n",
    "vector_index.save_local(folder_path)\n",
    "print(f\"FAISS index saved to '{folder_path}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93a23e4",
   "metadata": {},
   "source": [
    "Load Index, Create Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1a2110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain is ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Load the FAISS index from local storage ---\n",
    "vector_index_loaded = FAISS.load_local(\n",
    "    folder_path,\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# --- Create the RetrievalQA chain ---\n",
    "# We use RetrievalQA and set `return_source_documents=True` to ensure we get the source info.\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_index_loaded.as_retriever(),\n",
    "    return_source_documents=True  # This is the key change\n",
    ")\n",
    "\n",
    "print(\"Chain is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a777f568",
   "metadata": {},
   "source": [
    "Ask a Question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9ddf9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing query: 'Net direct tax revenue jumped ?'\n",
      "\n",
      "==================== RESULT ====================\n",
      "\n",
      "--- Answer ---\n",
      "Net direct tax revenue jumped 6.33% to over Rs 11.89 lakh crore till October 12 in the current fiscal year.\n",
      "\n",
      "--- Sources ---\n",
      "https://www.moneycontrol.com/news/business/economy/net-direct-tax-revenue-jumps-6-3-to-rs-11-89-lakh-crore-till-oct-12-13613684.html\n",
      "\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Execute the query ---\n",
    "query = \"Net direct tax revenue jumped ?\"\n",
    "print(f\"\\nExecuting query: '{query}'\")\n",
    "\n",
    "result = chain.invoke({\"query\": query})\n",
    "\n",
    "# --- Print the final answer and sources ---\n",
    "print(\"\\n\" + \"=\"*20 + \" RESULT \" + \"=\"*20)\n",
    "print(\"\\n--- Answer ---\")\n",
    "# The answer is now in the 'result' key\n",
    "print(result.get('result', 'No answer found.').strip())\n",
    "\n",
    "print(\"\\n--- Sources ---\")\n",
    "# Extract unique sources from the 'source_documents' metadata\n",
    "if 'source_documents' in result and result['source_documents']:\n",
    "    # Use a set to automatically handle duplicate URLs\n",
    "    unique_sources = {doc.metadata['source'] for doc in result['source_documents']}\n",
    "    for source in unique_sources:\n",
    "        print(source)\n",
    "else:\n",
    "    print(\"No sources found.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*48)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c855a201",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
